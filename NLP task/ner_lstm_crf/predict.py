import torch
import config
import pickle
from model import BiLSTM_CRF


def load_model():
    # åŠ è½½å­—å…¸
    with open(config.VOCAB_PATH, 'rb') as f:
        word2id, tag2id, id2tag = pickle.load(f)

    # æ¨¡å‹ç»“æ„
    model = BiLSTM_CRF(
        vocab_size=len(word2id),
        tagset_size=len(tag2id),
        embedding_dim=config.EMBEDDING_DIM,
        hidden_dim=config.HIDDEN_DIM
    )

    # åŠ è½½æƒé‡
    model.load_state_dict(torch.load(config.MODEL_SAVE_PATH, map_location='cpu'))
    model.eval()
    return model, word2id, id2tag


def predict(sentence, model, word2id, id2tag):
    tokens = list(sentence)
    input_ids = [word2id.get(char, word2id[config.UNK_TOKEN]) for char in tokens]
    input_tensor = torch.tensor([input_ids], dtype=torch.long)  # shape (1, seq_len)
    mask = torch.ones_like(input_tensor, dtype=torch.bool)

    with torch.no_grad():
        pred = model(input_tensor, mask=mask)[0]  # batch size 1

    tags = [id2tag[i] for i in pred]
    return list(zip(tokens, tags))


if __name__ == "__main__":
    model, word2id, id2tag = load_model()

    print("ğŸ‘‰ è¾“å…¥å¥å­è¿›è¡Œå®ä½“è¯†åˆ«ï¼ˆè¾“å…¥ q é€€å‡ºï¼‰")
    while True:
        sentence = input("\nè¯·è¾“å…¥å¥å­ï¼š")
        if sentence.lower() in {'q', 'quit', 'exit'}:
            break
        results = predict(sentence, model, word2id, id2tag)
        print("\nğŸ” å®ä½“è¯†åˆ«ç»“æœï¼š")
        for char, tag in results:
            print(f"{char}  -->  {tag}")
