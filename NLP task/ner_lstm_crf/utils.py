import os
import pickle
from collections import Counter
import config

def build_vocab(file_path):
    words = []
    tags = []

    # è¯»å–è®­ç»ƒæ•°æ®
    with open(file_path, encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            if len(line.split()) != 2:
                continue  # å¿½ç•¥æ ¼å¼å¼‚å¸¸è¡Œ
            word, tag = line.split()
            words.append(word)
            tags.append(tag)

    # æ„å»ºè¯è¡¨å’Œæ ‡ç­¾è¡¨
    word_counter = Counter(words)
    vocab = [config.PAD_TOKEN, config.UNK_TOKEN] + list(word_counter.keys())
    word2id = {word: idx for idx, word in enumerate(vocab)}

    tag_set = sorted(set(tags))
    tag2id = {tag: idx for idx, tag in enumerate(tag_set)}
    id2tag = {idx: tag for tag, idx in tag2id.items()}

    # åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(os.path.dirname(config.VOCAB_PATH), exist_ok=True)

    # ä¿å­˜ä¸º pickle
    with open(config.VOCAB_PATH, 'wb') as f:
        pickle.dump((word2id, tag2id, id2tag), f)

    print(f"âœ… å­—å…¸ä¿å­˜æˆåŠŸï¼š{config.VOCAB_PATH}")
    print(f"ğŸ“¦ å…± {len(word2id)} ä¸ªè¯ï¼Œ{len(tag2id)} ä¸ªæ ‡ç­¾")

if __name__ == "__main__":
    build_vocab(config.TRAINING_DATA_PATH)
