import torch
import torch.nn.functional as F
from model import ESIM
from utils import set_seed
from dataset import build_vocab, load_snli_data
import config

# æ ‡ç­¾æ˜ å°„ï¼ˆæ ¹æ® SNLI ç±»åˆ«ï¼‰
id2label = {
    0: "entailment",
    1: "neutral",
    2: "contradiction"
}

def tokenize(sentence):
    """
    ç®€å•åˆ†è¯å‡½æ•°ï¼šè‹±æ–‡æŒ‰ç©ºæ ¼åˆ†è¯ï¼Œä¸­æ–‡æŒ‰å­—åˆ†è¯
    """
    if all(ord(c) < 128 for c in sentence):
        return sentence.lower().split()  # è‹±æ–‡æŒ‰ç©ºæ ¼
    else:
        return list(sentence.strip())    # ä¸­æ–‡æŒ‰å­—

def encode_sentence(sentence, word2idx, max_len):
    tokens = tokenize(sentence)
    ids = [word2idx.get(token, word2idx.get("<UNK>", 0)) for token in tokens]
    ids = ids[:max_len] + [0] * (max_len - len(ids))
    return torch.tensor(ids, dtype=torch.long)

def load_model(word2idx):
    model = ESIM(
        vocab_size=len(word2idx),
        embedding_dim=config.embedding_dim,
        hidden_size=config.hidden_size,
        num_classes=config.num_classes
    )
    model.load_state_dict(torch.load(config.save_model_path, map_location=config.device))
    model.to(config.device)
    model.eval()
    return model

def predict(premise, hypothesis, model, word2idx):
    p_ids = encode_sentence(premise, word2idx, config.max_seq_len).unsqueeze(0).to(config.device)
    h_ids = encode_sentence(hypothesis, word2idx, config.max_seq_len).unsqueeze(0).to(config.device)

    with torch.no_grad():
        logits = model(p_ids, h_ids)
        probs = F.softmax(logits, dim=1)
        pred = torch.argmax(probs, dim=1).item()
        confidence = probs[0][pred].item()
        return id2label[pred], confidence

if __name__ == "__main__":
    set_seed(config.random_seed)

    # é‡å»ºè¯è¡¨ï¼ˆå¿…é¡»å’Œè®­ç»ƒä¿æŒä¸€è‡´ï¼‰
    print("ğŸ“š æ­£åœ¨åŠ è½½è¯è¡¨...")
    train_data = load_snli_data(config.train_file, max_samples=80000)
    word2idx = build_vocab(train_data, max_vocab_size=config.max_vocab_size)

    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹å‚æ•°...")
    model = load_model(word2idx)

    print("âœ¨ è¾“å…¥å‰æå’Œå‡è®¾å¥å­è¿›è¡Œé¢„æµ‹ï¼ˆè¾“å…¥ q é€€å‡ºï¼‰")
    while True:
        premise = input("\nè¯·è¾“å…¥å‰æå¥å­ï¼ˆPremiseï¼‰ï¼š")
        if premise.strip().lower() in {"q", "quit", "exit"}:
            break
        hypothesis = input("è¯·è¾“å…¥å‡è®¾å¥å­ï¼ˆHypothesisï¼‰ï¼š")
        if hypothesis.strip().lower() in {"q", "quit", "exit"}:
            break

        label, conf = predict(premise, hypothesis, model, word2idx)
        print(f"ğŸ” é¢„æµ‹ç»“æœï¼š{label}ï¼ˆç½®ä¿¡åº¦ï¼š{conf:.4f}ï¼‰")

